{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "FJNUwmbgGyua",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "89xtkJwZ18nB",
        "c49ITxTc407N",
        "k5UmGsbsOxih",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gawandegaurav60/Netflix-Movies-and-TV-Shows-Clustering/blob/main/ML_Capstone_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - NETFLIX MOVIES AND TV SHOWS CLUSTERING\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual/Team\n",
        "##### **Submitted By**    - Gaurav Gawande"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix is a subscription-based streaming service that provides its members with access to a vast library of movies and TV shows. With such a large content catalog, it can be challenging for users to find content that matches their preferences. To address this issue, Netflix uses data analysis and machine learning techniques such as clustering to group their content into similar categories. This approach involves analyzing various characteristics of each title, such as genre, cast, and plot, and using algorithms to identify patterns and similarities.\n",
        "\n",
        "Netflix Movies and TV Shows Clustering is a data-driven approach that aims to group the platform's vast library of content into similar categories using unsupervised machine learning algorithms. The primary objective of this clustering is to improve the user experience on Netflix by providing personalized content recommendations to users based on their viewing history and preferences. By organizing the content library into clusters, Netflix can suggest titles that are more likely to match user interests, leading to increased user engagement and satisfaction, which in turn can lead to increased retention and company revenue.\n",
        "\n",
        "The process of clustering involves analyzing various data points, such as genre, cast, director, plot, and other relevant features, and using clustering techniques such as k-means, hierarchical clustering, and principal component analysis (PCA) to identify patterns and similarities between different titles. Algorithms such as k-means are used to group movies and TV shows with similar features into distinct groups, each representing a unique genre or category. The hierarchical clustering technique is used to create a tree-like structure that groups movies and TV shows into similar categories based on their characteristics.\n",
        "\n",
        "Clustering is a powerful tool that enables Netflix to analyze and group its vast library of content into similar categories, providing users with personalized recommendations and improving the overall user experience. This approach is data-driven, and algorithms such as k-means, hierarchical clustering, and recommender system are used to identify patterns and similarities between different titles, which helps Netflix make informed decisions about content production and licensing.\n",
        "\n",
        "One of the most significant benefits of clustering for Netflix is that it allows the platform to provide personalized recommendations to users based on their viewing history and preferences. By analyzing users' data and identifying patterns and similarities between different titles, Netflix can recommend content that is more likely to match users' interests. This approach leads to increased user engagement and satisfaction, which can ultimately lead to increased retention and company revenue.\n",
        "\n",
        "Clustering also helps Netflix make data-driven decisions about content production and licensing. By understanding underlying trends and patterns in user behavior, Netflix can make informed decisions about which titles to produce or acquire and which to remove from its platform. This approach can help the platform to optimize its content library and offer titles that are more likely to be successful with its user base.\n",
        "\n",
        "In conclusion, Netflix Movies and TV Shows Clustering is a powerful tool that enables the platform to group its vast library of content into similar categories, providing users with personalized recommendations and improving the overall user experience. This approach is data-driven and relies on unsupervised machine learning algorithms such as k-means, hierarchical clustering, and recommender system to identify patterns and similarities between different titles. Clustering helps Netflix make informed decisions about content production and licensing and ultimately leads to increased customer retention and company revenue."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/gawandegaurav60/Netflix-Movies-and-TV-Shows-Clustering"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As one of the world's largest streaming platforms, Netflix offers a vast library of movies and TV shows. However, with so many options to choose from, it can be challenging for users to find content that matches their preferences.\n",
        "\n",
        "To address this challenge, this project aims to use unsupervised learning techniques to cluster similar movies and TV shows on Netflix. By grouping titles with similar attributes, we can provide users with more targeted recommendations, and help them find new content they will enjoy.\n",
        "\n",
        "Specifically, this project will involve analyzing a dataset of Netflix titles, including features such as genre, release year, cast, and plot summary, among others. By applying clustering algorithms such as K-Means or Hierarchical clustering, we aim to identify groups of movies and TV shows with similar attributes.\n",
        "\n",
        "Ultimately, the project aims to create a clustering model that can accurately group Netflix titles based on their characteristics. This model can then be used to make recommendations to users or to help Netflix improve its content discovery algorithms."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "\n",
        "## Data Visualisation Libraray\n",
        "import matplotlib.pyplot as plt\n",
        "import missingno as msno\n",
        "import matplotlib.cm as cm\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "# libraries used to process textual data\n",
        "import string\n",
        "string.punctuation\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# libraries used to implement clusters\n",
        "from sklearn.metrics import silhouette_score\n",
        "from yellowbrick.cluster import SilhouetteVisualizer\n",
        "from sklearn.metrics import silhouette_samples\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import DBSCAN\n",
        "from scipy.cluster.hierarchy import dendrogram\n",
        "from scipy.cluster.hierarchy import linkage\n",
        "\n",
        "# Library of warnings would assist in ignoring warnings issued\n",
        "import warnings;warnings.filterwarnings('ignore')\n",
        "import warnings;warnings.simplefilter('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/AlmaBetter/Module 6/Capstone Project/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv')"
      ],
      "metadata": {
        "id": "6e_L1hvKlh0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "LNGKF2mKmg5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(df[df.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "plt.rcParams[\"figure.figsize\"] = (8, 6)\n",
        "sns.heatmap(df.isnull(), cbar=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset used for Netflix movies and TV shows clustering includes information on multiple features of the titles, such as genre, director, cast, rating, release year, duration, and type. It consists of 7787 rows and 12 columns.\n",
        "\n",
        "However, some columns, such as director, cast, and country, contain null values that need to be addressed during the data analysis process."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe(include=\"all\")"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "show_id : Unique ID for every Movie / Tv Show\n",
        "\n",
        "type : Identifier - A Movie or TV Show\n",
        "\n",
        "title : Title of the Movie / Tv Show\n",
        "\n",
        "director : Director of the Movie\n",
        "\n",
        "cast : Actors involved in the movie / show\n",
        "\n",
        "country : Country where the movie / show was produced\n",
        "\n",
        "date_added : Date it was added on Netflix\n",
        "\n",
        "release_year : Actual Releaseyear of the movie / show\n",
        "\n",
        "rating : TV Rating of the movie / show\n",
        "\n",
        "duration : Total Duration - in minutes or number of seasons\n",
        "\n",
        "listed_in : Genere\n",
        "\n",
        "description : The Summary description"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "columns = ['show_id', 'type', 'title', 'director', 'cast', 'country', 'date_added',\n",
        "       'release_year', 'rating', 'duration', 'listed_in', 'description']\n",
        "\n",
        "for column in df.columns:\n",
        "    unique_values = df[column].unique()\n",
        "    print(f\"Unique values in column '{column}': {unique_values}\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dealing with Null values"
      ],
      "metadata": {
        "id": "nCsd1q9go8PA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "print('Missing Data Count')\n",
        "df.isna().sum()[df.isna().sum() > 0].sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The missing values in the 'director', 'cast', and 'country' columns can be replaced with the label 'Unknown'.\n",
        "df[['director']] = df[['director']].fillna('Unknown')\n",
        "df[['cast']]     = df[['cast']].fillna('Unknown')\n",
        "df[['country'] ] = df[['country']].fillna('Unknown')"
      ],
      "metadata": {
        "id": "B6cYbCzYpEIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For the missing values in the 'rating' column, we can replace them with the 'mode'value of rating since this attribute is discrete.\n",
        "df['rating'].fillna(value=df['rating'].mode()[0],inplace=True)\n",
        "df.dropna(subset=['date_added'], inplace=True)"
      ],
      "metadata": {
        "id": "zbxwOGZZpEE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "FuA6Fq-bpT8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "zECrhjU1pT4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To simplify the analysis, we will choose the primary country and primary genre for each entry in the dataframe.\n",
        "df['country'] = df['country'].apply(lambda x: x.split(',')[0])\n",
        "df['listed_in'] = df['listed_in'].apply(lambda x: x.split(',')[0])\n",
        "df['duration'] = df['duration'].apply(lambda x: int(x.split()[0]))"
      ],
      "metadata": {
        "id": "T2E5wiWVqBFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# datatype of duration\n",
        "df.duration.dtype"
      ],
      "metadata": {
        "id": "H7ZrUAQMqBCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(df.dtypes).rename(columns = {0:'dtype'})\n"
      ],
      "metadata": {
        "id": "TMMwaq3pqA-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#addding new column to dataframe such as 'month_added'and 'year_added' to gain more insights from the data\n",
        "df['year_added'] = df['date_added'].dt.year\n",
        "df['month_added'] = df['date_added'].dt.month"
      ],
      "metadata": {
        "id": "wJad8YtCqI-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing the values in the rating column\n",
        "# Create a dictionary to map the current ratings to new ratings\n",
        "rating_map = {'TV-MA':'Adults',\n",
        "'R':'Adults',\n",
        "'PG-13':'Teens',\n",
        "'TV-14':'Young Adults',\n",
        "'TV-PG':'Older Kids',\n",
        "'NR':'Adults',\n",
        "'TV-G':'Kids',\n",
        "'TV-Y':'Kids',\n",
        "'TV-Y7':'Older Kids',\n",
        "'PG':'Older Kids',\n",
        "'G':'Kids',\n",
        "'NC-17':'Adults',\n",
        "'TV-Y7-FV':'Older Kids',\n",
        "'UR':'Adults'}\n",
        "# Replace the current ratings with the new ratings using the mapping dictionary\n",
        "df['rating'].replace(rating_map,inplace=True)\n",
        "# Print the unique values in the 'rating' column to verify that the changes have been made\n",
        "print(df['rating'].unique())"
      ],
      "metadata": {
        "id": "rhtolEzKqI7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Replaced missing values in the 'director', 'cast', and 'country' columns with the label 'Unknown'.\n",
        "\n",
        "Imputing missing values in the 'rating' column with the mode.\n",
        "\n",
        "Choosed the primary country and primary genre for each entry in the dataframe to simplify the analysis.\n",
        "\n",
        "Transformed the 'duration' column in the dataframe by splitting the string value on whitespace delimiter and converting it into an integer datatype.\n",
        "\n",
        "Converted the timestamp in the 'date_added' column to datetime format to fetch other details.And added new columns to the dataframe, such as 'month_added' and 'year_added', to gain more insights from the data.\n",
        "\n",
        "Changed the values in the rating column by Creating a dictionary to map the current ratings to new ratings."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "type_counts = df['type'].value_counts()\n",
        "plt.bar(type_counts.index, type_counts.values)\n",
        "plt.xlabel('Content Type')\n",
        "plt.ylabel('Number of Titles')\n",
        "plt.title('Distribution of Movies and TV Shows in Netflix Dataset')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart is a common choice for displaying the distribution of categorical data, such as the number of movies and TV shows in the Netflix dataset. It allows for easy comparison between categories and can provide a clear visualization of the overall distribution of content types in the dataset. Therefore, a bar chart is an appropriate choice for this specific dataset and research question."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The majority of the content in the Netflix dataset is Movies, as they have a higher count than TV shows.\n",
        "\n",
        "The distribution of movies and TV shows in the Netflix dataset is not equal, which indicates that Netflix has a preference towards movies.\n",
        "\n",
        "The number of TV shows in the dataset is still significant, which suggests that Netflix also invests in producing and acquiring TV shows for its platform."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The insights gained from the chart may help create a positive business impact for Netflix. Knowing that the majority of the content in the Netflix dataset is Movies, and that Netflix has a preference towards Movies, may inform decisions related to content production and acquisition. For instance, Netflix may choose to allocate more resources towards producing and acquiring Movies in order to attract more viewers and subscribers.\n"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "top_directors = df.loc[df['director'] != 'Unknown', 'director'].value_counts().nlargest(10)\n",
        "plt.figure(figsize=(15,6))\n",
        "plt.bar(top_directors.index, top_directors.values)\n",
        "plt.title('Top 10 Directors by Number of Shows Directed')\n",
        "plt.xlabel('Director')\n",
        "plt.ylabel('Number of Shows')\n",
        "plt.xticks(rotation=30)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar chart that displays the top 10 directors by the number of shows they directed in the Netflix dataset. This chart is an appropriate choice for analyzing the relationship between directors and the number of shows they have directed on Netflix, and it can provide valuable insights into the most popular directors on the platform. The use of color in the chart also makes it visually appealing and easy to read."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The top director by the number of shows directed is Raul Campos, Jan Suter who directed 18 shows in the dataset.\n",
        "\n",
        "The second most popular director is Marcus Raboy, who directed 16 shows.\n",
        "\n",
        "Most of the top 10 directors have directed between 7-11 shows on Netflix.\n",
        "\n",
        "The top 10 directors are mostly from the US, except for David Dhawan from India, who directed 9 shows on Netflix."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These insights may help inform decisions related to content production and acquisition, as they provide information about the most popular directors on Netflix and their past work.\n"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "filtered_df = df[~(df['cast']=='Unknown')]\n",
        "split_cast = filtered_df['cast'].str.split(', ', expand=True)\n",
        "cast_values = split_cast.stack().reset_index(level=1, drop=True)\n",
        "top_10_actors = cast_values.value_counts().nlargest(10)\n",
        "top_10_actors.plot(kind='bar', figsize=(13,5))\n",
        "plt.title('Top 10 Actors by Number of Shows', fontsize=14)\n",
        "plt.ylabel('Number of Shows', fontsize=12)\n",
        "plt.xticks(rotation=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bar chart that displays the top 10 actors by the number of shows they appeared in on Netflix. This chart is an appropriate choice for analyzing the relationship between actors and the number of shows they appeared in on Netflix, and it can provide valuable insights into the most popular actors on the platform."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The top actor by the number of shows they appeared in is Anupam Kher, who appeared in 42 shows in the dataset.\n",
        "\n",
        "The second most popular actor is Shah Rukh Khan, who appeared in 35 shows.\n",
        "\n",
        "Most of the top 10 actors have appeared in between 25-30 shows on Netflix.\n",
        "\n",
        "The top 10 actors are mostly from India, with the exception of Takahiro Sakurai and Yuki Kaji from the Japan."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By knowing the most popular actors on the platform, Netflix can acquire or produce content that features these actors, which could increase the number of viewership and engagement on their platform.\n",
        "\n",
        "The insights can also help in identifying the target audience for different titles, as different actors may appeal to different demographics.\n",
        "\n",
        "The data can also help Netflix identify trends and preferences among its user base, which could help inform decisions related to content acquisition and production."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "top_countries = df.loc[df['country'] != 'Unknown', 'country'].value_counts().nlargest(10)\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.barh(top_countries.index, top_countries.values)\n",
        "plt.title('Top 10 Countries with the Highest Number of Shows')\n",
        "plt.xlabel('Number of Shows')\n",
        "plt.ylabel('Country')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked this chart because it shows the top 10 countries with the highest number of movies and TV shows in the dataset, which is important information for any business looking to enter or expand its operations in the global streaming market."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that the United States is by far the largest producer of movies and TV shows in the dataset, with over 2,500 titles. The next highest producing countries are India, the United Kingdom, and Canada, each with around 500-1000 titles. Other countries in the top 10 include France, Japan, and Spain. The top 3 countries (USA, India, UK) account for 56.69% of shows in the dataset, while the top 10 countries account for 73.19% of shows."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights can definitely help create a positive business impact. For instance, knowing that the US is the largest producer of movies and TV shows can help streaming companies plan their content acquisition strategy and marketing efforts accordingly. Additionally, the insight that the top 3 countries account for over half of the shows in the dataset can help companies focus their attention on these markets to maximize their viewership."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "top_genres = df[\"listed_in\"].value_counts().head(10)\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.pie(top_genres, labels=top_genres.index, autopct='%1.1f%%', pctdistance=0.8, labeldistance=1.1,radius=1.2, startangle=90, counterclock=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked the pie chart because it's a great way to show the distribution of categorical data. In this case, we are looking at the distribution of the top 10 genres in the Netflix dataset."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pie chart shows the percentage share of each of the top 10 genres in the dataset. The insight we can gain from this chart is that the most popular genre in the dataset is dramas, followed by comedies and documentries. It also shows that the top 10 genres make up a significant portion of the dataset."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights from the chart can help create a positive business impact by allowing Netflix to better understand the content preferences of their audience. They can use this information to make more informed decisions about what type of content to acquire and produce, which can help increase their viewership and revenue."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "df_rating = df['rating'].value_counts()\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.pie(df_rating.values, labels=df_rating.index,autopct='%1.1f%%',startangle=90)\n",
        "plt.title('Distribution of Ratings')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked this chart to visualize the distribution of content ratings in the Netflix dataset. Pie charts are effective for showing the proportion of data within different categories, which is exactly what this chart aims to show"
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From this chart, we can see that the most common rating in the Netflix dataset is Adults (TV-MA - Mature Audiences), which accounts for almost 47% of all titles. This is followed by Young Adults (TV-14 - Parents Strongly Cautioned) and Older Kids (TV-PG - Parental Guidance Suggested), which account for about 25% and 17% of titles, respectively."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These insights could help create a positive business impact by informing decisions about content acquisition and creation. For example, the fact that TV-MA is the most common rating suggests that there is a strong demand for mature content on the platform, which could inform decisions about which types of content to acquire or produce."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "df_month_added = df['month_added'].value_counts()\n",
        "plt.title('Months Value Count')\n",
        "df_month_added.plot(kind='bar', figsize=(13,5))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart is a bar plot showing the number of TV shows and movies added to Netflix for each month in the dataset. The code uses the seaborn library to create the plot."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insights that can be gained from this chart include identifying the months with the highest and lowest number of additions to Netflix. This information could help Netflix plan their content acquisition strategy and release schedule. For example, if a particular month consistently has a low number of additions, Netflix may choose to focus their content acquisition efforts during that time to attract more viewers.\n",
        "\n",
        "From bar plot we can see that highest number of movies added from 10th month to 1st i.e. from Octomber to January."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart doesn't necessarily lead to negative growth insights, but it could identify areas for improvement. If there are particular months with low numbers of additions, Netflix may need to consider acquiring more content during those months or releasing more original content to fill the gaps. Additionally, if there are months with a high number of additions, Netflix may need to consider adjusting their release schedule to avoid overcrowding the platform with too much content at once."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "tv_shows = df[df['type'] == 'TV Show']\n",
        "plt.figure(figsize=(15, 7))\n",
        "plt.hist(tv_shows['duration'], bins=20, edgecolor='black')\n",
        "plt.xlabel('Number of Seasons', fontsize=12)\n",
        "plt.ylabel('Number of Shows', fontsize=12)\n",
        "plt.title('Number of Seasons per TV Show Distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart is a histogram that shows the distribution of the number of seasons per TV show in the dataset. It can provide insights into the most common length of TV shows and the distribution of the data."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The majority of TV shows have one to three seasons.\n",
        "\n",
        "There are some TV shows with more than 10 seasons, but they are rare."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This insight could help Netflix make decisions about the number of seasons to order for new shows. It suggests that shorter seasons may be more popular and more likely to be successful.\n",
        "\n",
        "This information could also help inform negotiations with production companies for the length of a TV show."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "df_release_year = df.groupby(['release_year', 'type'])['show_id'].count().reset_index()\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.lineplot(data=df_release_year, x='release_year', y='show_id', hue='type')\n",
        "plt.title('Number of Movies and TV Shows Released Each Year')\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked this chart because it provides an interesting insight into the distribution of movies and TV shows over time. The line plot shows the trend in the number of movies and TV shows released each year, and the different lines for movies and TV shows make it easy to compare the two. This chart also uses color coding to differentiate between movies and TV shows, which helps to make the chart more visually appealing and easier to understand. Overall, this chart is an effective way to explore the relationship between release year and the number of movies and TV shows released."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe the number of movies and TV shows released each year, which can provide us insights on the trend of media content production over the years.\n",
        "\n",
        "We can see that the number of movies produced has increased significantly from the mid-2000s to 2020.\n",
        "\n",
        "The number of TV shows produced has also increased, but not as much as TV shows.\n",
        "\n",
        "The chart also shows a dip in movie production in 2020, which may be due to the COVID-19 pandemic."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights can help in creating a positive business impact, as it can provide valuable information for content creators, streaming platforms, and investors. For example, the increase in the production of movies may indicate a shift in consumer preferences towards movies, which can be used to guide content creation and platform offerings. However, the COVID-19 pandemic causing a dip in movie production can be a negative impact, as it may lead to a shortage of new content for streaming platforms and reduced revenue for content creators."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "filtered_df = df[df['release_year'] >= 2008]\n",
        "plt.figure(figsize=(15, 7))\n",
        "sns.countplot(x='release_year', data=filtered_df, hue='type', order=range(2008, 2022))\n",
        "plt.xlabel('Release Year')\n",
        "plt.ylabel('Number of Shows')\n",
        "plt.title('Number of Shows Released Each Year Since 2008 on Netflix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I picked this chart because it shows the trend of the number of shows released each year since 2008, and it also shows the difference in the number of movies and TV shows released each year."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of TV shows released each year has been increasing steadily since 2008.\n",
        "\n",
        "The number of TV shows released each year has been relatively stable with some fluctuations.\n",
        "\n",
        "The difference between the number of movies and TV shows released each year has been increasing over time, indicating a shift towards more original movies content on Netflix."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights could help in creating a positive business impact by providing insights into the trend of content production on Netflix. By understanding the trend, Netflix can make strategic decisions on the type and quantity of content to produce in the future.\n",
        "\n",
        "There are no insights that lead to negative growth in this chart."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "df_country = df.groupby(['country', 'type'])['show_id'].count().reset_index()\n",
        "df_country = df_country.sort_values(by='show_id', ascending=False)\n",
        "plt.figure(figsize=(15, 6))\n",
        "sns.barplot(data=df_country[:20], x='country', y='show_id', hue='type')\n",
        "plt.xticks(rotation=90)\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Top 20 Countries by Number of Shows on Netflix')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Number of Shows')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart was chosen because it provides insights into the top 20 countries with the highest number of shows on Netflix, based on the country and show type. It helps to identify the countries that have the most content available, which could be useful for content acquisition and localization strategies."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that the United States has by far the most content available on Netflix, with over 2,000 shows. This is followed by India with over 800 shows and the United Kingdom with over 300 shows. The chart also shows that the majority of the content available in these countries are movies, with the exception of United Kingdom, which has a relatively even split between movies and TV shows."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the gained insights can help to create a positive business impact by informing content acquisition and localization strategies. For example, if a company is looking to expand its content library in a particular region, they can use this chart to identify the countries with the most content and prioritize acquiring content from those regions. The chart can also be used to inform localization strategies, such as dubbing or subtitling, for the countries with the highest number of shows on Netflix. By providing localized content for these regions, companies can attract more viewers and increase their overall revenue."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "tv_shows = df[(df['type'] == 'TV Show') & ~(df['cast'] == 'Unknown')]\n",
        "# Counting the number of TV shows each actor has appeared in\n",
        "actor_counts = tv_shows['cast'].str.split(', ').explode().value_counts()\n",
        "top_actors = actor_counts.head(10)\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.barh(top_actors.index, top_actors.values)\n",
        "plt.xlabel('Number of TV Shows', fontsize=12)\n",
        "plt.ylabel('Actor Name for TV Shows', fontsize=12)\n",
        "plt.title('Actors with the Most TV Show Appearances', fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chart visualize the top 10 actors with the most TV show appearances in a horizontal bar plot. This chart could be useful for understanding which actors are most frequently cast in TV shows and may be of interest to individuals in the entertainment industry or those interested in popular culture."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows the top 10 actors who have appeared in the most TV shows on Netflix. The insight gained from the chart is that Takahiro Sakurai has appeared in the most TV shows on Netflix, followed by Yuki kaji and Daisuke Ono. These insights could be used to identify popular actors that could potentially draw in audiences for new TV show releases."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The gained insights could help creating a positive business impact by improving the selection of actors for TV shows. If popular actors are cast in a TV show, it could potentially attract more viewers, leading to a positive impact on the business. However, it is important to note that the popularity of an actor does not necessarily guarantee success, as the quality of the TV show itself is also a significant factor."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "comment_words = ' '.join(df['description'].astype(str).str.lower())\n",
        "stopwords = set(STOPWORDS)                                   # Define the stopwords\n",
        "wordcloud = WordCloud(width=800, height=800,\n",
        "                      background_color='black',\n",
        "                      stopwords=stopwords,\n",
        "                      min_font_size=10).generate(comment_words)\n",
        "plt.figure(figsize=(10,5), facecolor=None)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code generates a word cloud from the descriptions of all the shows and movies in the Netflix dataset. Since this chart is a visualization of text data, it is a good choice to quickly see the most commonly occurring words in the descriptions. It gives an insight into the themes and genres of the shows and movies on Netflix.\n"
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights gained from this chart could be the most common words and phrases that are used in the descriptions. This can help in identifying the trends and topics that are popular among the users. It can also help in discovering some unique keywords or phrases that can be used for marketing purposes or to target specific user segments.\n",
        "\n",
        "As we can see in wordcloud, most common words in description are Life, Family, Friend, Love etc."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These insights can help create a positive business impact by allowing Netflix to better understand the interests of its users and tailor its content to meet those interests. By identifying popular themes and genres, Netflix can create more targeted marketing campaigns and improve the overall user experience."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "\n",
        "numeric_columns = df.select_dtypes(include=['number']).columns\n",
        "df[numeric_columns] = df[numeric_columns].astype(float)\n",
        "\n",
        "# Drop non-numeric columns\n",
        "df_numeric = df.select_dtypes(include=['number'])\n",
        "\n",
        "# Compute correlation matrix\n",
        "correlation = df_numeric.corr()\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation, annot=True, cmap='mako')\n",
        "plt.title('Correlation Heatmap (Numeric Columns Only)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The heatmap shows the correlation coefficients between different numerical columns of the Netflix dataset.\n",
        "\n",
        "The heatmap uses a color scale to represent the correlation coefficients, where light colour represents positive correlation, dark colour represents negative correlation. The annotation parameter is set to True, which displays the correlation coefficient value inside each cell of the heatmap"
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This visualization can be helpful in identifying the strength and direction of the relationship between different variables in the dataset. By analyzing the heatmap, we can see which variables have a strong positive or negative correlation with each other. This information can be useful in making predictions and building machine learning models.\n",
        "\n",
        "Overall, this heatmap can provide valuable insights into the relationships between different variables in the Netflix dataset.\n",
        "\n",
        "We can see that duration and release year are negatively correlated by 24%.\n",
        "\n",
        "Year added and release year are positively correlated by 10%.\n"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pair plot provides a scatter plot matrix of all numerical variables in the dataset, and histograms along the diagonal which can help visualize the relationships between each pair of variables.\n"
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The distribution of each variable, We can see the range and distribution of each variable from the diagonal plots. The distribution of the duration of movies and TV shows seems to be concentrated in certain ranges.\n",
        "\n",
        "Correlation between variables, We can see the scatter plots of each pair of variables, as well as the correlation coefficient in the upper-right corner of each plot. There seems to be a positive correlation between the release year and the duration of movies and TV shows, indicating that newer movies and TV shows tend to be longer.\n",
        "\n",
        "Outlier, We can also see any outliers in the data from the scatter plots. There seems to be a movie with a very long duration compared to the rest of the dataset."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hypothesis 1: The difference in the average duration of movies and TV shows on Netflix.\n",
        "\n",
        "Hypothesis 2: Difference in the average number of seasons for TV shows on Netflix between those produced in the United States and those produced outside of the United States.\n",
        "\n",
        "Hypothesis 3: The number of TV shows added to Netflix has increased over time."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement 1: The difference in the average duration of movies and TV shows on Netflix"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis(H0) - There is no significant difference in the average duration of movies and TV shows on Netflix.\n",
        "\n",
        "Alternative Hypothesis(H1) - There is a significant difference in the average duration of movies and TV shows on Netflix."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Extract the durations of movies and TV shows from the dataset\n",
        "movie_durations = df[df['type'] == 'Movie']['duration']\n",
        "tv_show_durations = df[df['type'] == 'TV Show']['duration']\n",
        "\n",
        "# Perform two-sample t-test\n",
        "stat, p = ttest_ind(movie_durations, tv_show_durations, equal_var=False)\n",
        "\n",
        "# Print the test statistic and p-value\n",
        "print(\"Two-sample t-test statistic:\", stat)\n",
        "print(\"p-value:\", p)\n",
        "\n",
        "# Interpret the result\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "    print(\"Failed to reject null hypothesis.\")\n",
        "else:\n",
        "    print(\"Reject null hypothesis.\")"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The statistical test used to obtain the p-value is the two-sample t-test. This test was chosen because we are comparing the means of two independent samples (movie durations and TV show durations), and we want to determine whether the difference between the sample means is statistically significant or could have occurred by chance."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The two-sample t-test assumes that the samples are normally distributed, the variances of the two samples are not equal, and the samples are independent. In this case, we assumed that the duration of movies and TV shows on Netflix are normally distributed, and that the two samples are independent. The assumption of unequal variances was also made because the variance of movie durations and TV show durations may be different due to the nature of the content"
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement 2: Difference in the average number of seasons for TV shows on Netflix between those produced in the United States and those produced outside of the United States."
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis : There is no significant difference in the average number of seasons for TV shows on Netflix between those produced in the United States and those produced outside of the United States.\n",
        "\n",
        "Alternate hypothesis : There is a significant difference in the average number of seasons for TV shows on Netflix between those produced in the United States and those produced outside of the United States."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Extract the number of seasons for TV shows produced in the US and outside the US\n",
        "us_shows = df[(df['type'] == 'TV Show') & (df['country'] == 'United States')]\n",
        "us_shows_seasons = us_shows['duration'].apply(lambda x: int(x.split(' ')[0]) if isinstance(x, str) and 'season' in x else 0)\n",
        "\n",
        "non_us_shows = df[(df['type'] == 'TV Show') & (df['country'] != 'United States')]\n",
        "non_us_shows_seasons = non_us_shows['duration'].apply(lambda x: int(x.split(' ')[0]) if isinstance(x, str) and 'season' in x else 0)\n",
        "\n",
        "# Perform two-sample t-test\n",
        "stat, p = ttest_ind(us_shows_seasons, non_us_shows_seasons, equal_var=False)\n",
        "\n",
        "# Print the test statistic and p-value\n",
        "print(\"Two-sample t-test statistic:\", stat)\n",
        "print(\"p-value:\", p)\n",
        "\n",
        "# Interpret the result\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "    print(\"Failed to reject null hypothesis.\")\n",
        "else:\n",
        "    print(\"Reject null hypothesis.\")"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The statistical test used here is a two-sample t-test. This test is used to compare the means of two independent samples and determine if they are statistically different from each other"
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, we are comparing the number of seasons of TV shows produced in the US and outside the US. We chose this test because we want to determine if there is a statistically significant difference in the mean number of seasons between the two groups. We also assumed that the variances of the two groups are not equal, so we set the equal_var parameter to False when calling the ttest_ind() function."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement 3: The number of TV shows added to Netflix has increased over time."
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null hypothesis: The mean number of TV shows added to Netflix per year has not changed over time.\n",
        "\n",
        "Alternative hypothesis: The mean number of TV shows added to Netflix per year has increased over time."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy import stats\n",
        "\n",
        "# Extract the year from the date_added column\n",
        "df['year_added'] = pd.DatetimeIndex(df['date_added']).year\n",
        "\n",
        "# Extract the number of TV shows added to Netflix each year\n",
        "tv_shows = df[df['type'] == 'TV Show']\n",
        "tv_shows_by_year = tv_shows.groupby('year_added').size()\n",
        "\n",
        "# Perform a linear regression to test for a positive slope (i.e., an increase over time)\n",
        "slope, intercept, r_value, p_value, std_err = stats.linregress(tv_shows_by_year.index, tv_shows_by_year)\n",
        "\n",
        "# Print the p-value\n",
        "print(\"p-value:\", p_value)\n",
        "\n",
        "# Interpret the result\n",
        "alpha = 0.05\n",
        "if p_value > alpha:\n",
        "    print(\"Failed to reject null hypothesis.\")\n",
        "else:\n",
        "    print(\"Reject null hypothesis.\")"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, a linear regression is performed using the stats.linregress function from the scipy module. The purpose of the regression is to test for a positive slope (i.e., an increase over time) in the number of TV shows added to Netflix each year. The p-value is then calculated based on the results of the regression.\n",
        "\n",
        "A p-value is a measure of the evidence against the null hypothesis. In this case, the null hypothesis is that the number of TV shows added to Netflix has not increased over time (i.e., the slope is zero). The alternative hypothesis is that the number of TV shows added to Netflix has increased over time (i.e., the slope is positive)."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The specific statistical test used in this code is a linear regression with a hypothesis test on the slope coefficient. This is appropriate because we are interested in testing for a trend over time, and a linear regression allows us to model the relationship between the year and the number of TV shows added to Netflix. The p-value calculated from the regression provides evidence for or against the alternative hypothesis that there is a positive trend."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "None needed"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "sns.boxplot(data=df)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "None needed"
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction\n",
        "df['organized'] =(df['description'].astype(str) + ' ' +\n",
        "                  df['listed_in'].astype(str)   + ' ' +\n",
        "                  df['rating'].astype(str)      + ' ' +\n",
        "                  df['cast'].astype(str)        + ' ' +\n",
        "                  df['country'].astype(str)     + ' ' +\n",
        "                  df['director'].astype(str))"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.organized[0]"
      ],
      "metadata": {
        "id": "v319h-bghc7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "df['Lower_casing']= df['organized'].str.lower()\n",
        "df.Lower_casing[0]"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "[punc for punc in string.punctuation]"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(text):\n",
        "    # remove punctuation from text\n",
        "    return text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "df['cleaned_text'] = df['Lower_casing'].apply(remove_punctuation)\n",
        "\n",
        "df.cleaned_text[0]"
      ],
      "metadata": {
        "id": "w9maSNdnnnUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "import re\n",
        "\n",
        "def cleaned(x):\n",
        "    return re.sub(r\"[^a-zA-Z ]\", \"\", str(x))\n",
        "\n",
        "def remove_urls(text):\n",
        "    cleaned_text = re.sub(r'http\\S+', '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def remove_digits(text):\n",
        "    cleaned_text = re.sub(r'\\w*\\d\\w*', '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "df['removed_words']  = df['cleaned_text'].apply(cleaned)\n",
        "df['removed_url']    = df['removed_words'].apply(remove_urls)\n",
        "df['removed_digits'] = df['removed_url'].apply(remove_digits)"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    cleaned_text = ' '.join(words)\n",
        "    return cleaned_text\n",
        "\n",
        "df['removed_stopwords'] = df['removed_digits'].apply(remove_stopwords)\n",
        "df.removed_stopwords[0]"
      ],
      "metadata": {
        "id": "PjzPks0GoFMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces\n",
        "def remove_whitespaces(text):\n",
        "    cleaned_text = text.strip()\n",
        "    return cleaned_text\n",
        "\n",
        "df['removed_whitespaces']=df['removed_stopwords'].apply(remove_whitespaces)\n",
        "df['removed_whitespaces'].head()"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "def tokenize_text(text):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    return tokens\n",
        "\n",
        "df['tokenized'] = df['removed_whitespaces'].apply(tokenize_text)\n",
        "\n",
        "df['tokenized'].head()"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_text(tokens):\n",
        "    stemmer = SnowballStemmer('english')          # apply stemming to tokens\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "    lemmatizer = WordNetLemmatizer()              # apply lemmatization\n",
        "    normalized_tokens = [lemmatizer.lemmatize(token) for token in stemmed_tokens]\n",
        "    normalized_text = ' '.join(normalized_tokens) # join normalized tokens\n",
        "    return normalized_text\n",
        "\n",
        "df['normalized'] = df['tokenized'].apply(normalize_text)\n",
        "\n",
        "df['normalized'].head()"
      ],
      "metadata": {
        "id": "xafuzQ5YotC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text\n",
        "new_df = df[['title', 'normalized']]\n",
        "new_df.head()"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using tfidf\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "t_vectorizer = TfidfVectorizer(max_features=20000)\n",
        "x= t_vectorizer.fit_transform(new_df['normalized'])\n",
        "\n",
        "x.shape"
      ],
      "metadata": {
        "id": "rqZK0U9tpBmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used the TF-IDF (Term Frequency-Inverse Document Frequency) text vectorization technique. This technique is commonly used for text classification and information retrieval tasks. It assigns weights to each word in the document based on its frequency and rarity across the corpus. This helps to highlight the most important words in the document and down-weight the common words that do not provide much useful information for the analysis."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes.\n",
        "\n",
        "As the number of features (words in this case) is high, it is useful to apply dimensionality reduction to simplify the dataset and improve computational efficiency."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA()\n",
        "pca.fit(x.toarray())"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the cumulative explained variance ratio\n",
        "cumulative_var_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
        "\n",
        "# Plot the cumulative explained variance ratio versus the number of components\n",
        "plt.figure(figsize=(5, 5), dpi=120)\n",
        "plt.plot(cumulative_var_ratio)\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Cumulative Explained Variance Ratio')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VXsrwkbvp03z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_tuned = PCA(n_components=0.95)\n",
        "x_dense = x.toarray()\n",
        "pca_tuned.fit(x_dense)\n",
        "x = pca_tuned.transform(x_dense)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "OlwnegUGp0zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "IbCp21O5p0up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, PCA (Principal Component Analysis) has been used for dimensionality reduction. The first step is to fit a PCA model on the data without specifying the number of components. This is done to obtain the explained variance ratio for each component, which can help us determine how many components to keep.\n",
        "\n",
        "Next, a new PCA model is created with n_components set to 0.95, indicating that we want to keep enough components to explain 95% of the variance in the data. Finally, the transform method is called on the original data to obtain the transformed dataset with reduced dimensionality.\n",
        "\n",
        "Overall, the aim of this code is to reduce the dimensionality of the text data without losing too much information, in order to improve the efficiency of subsequent analysis."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely."
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "\n",
        "def evaluate_clustering_model(model, X, y_predict):\n",
        "    \"\"\"\n",
        "    Evaluate a clustering model and print the results.\n",
        "    & Returns\n",
        "    Model evaluation result\n",
        "    \"\"\"\n",
        "    # Calculate the number of clusters and evaluation metrics\n",
        "    n_clusters = len(set(y_predict))\n",
        "    S_score = silhouette_score(X, y_predict)\n",
        "    CH_score = calinski_harabasz_score(X, y_predict)\n",
        "    DB_score = davies_bouldin_score(X, y_predict)\n",
        "\n",
        "    # Print the evaluation results\n",
        "    print(f\"Number of clusters: {n_clusters}\")\n",
        "    print(f\"Silhouette score: {S_score:.4f}\")\n",
        "    print(f\"Calinski-Harabasz score: {CH_score:.4f}\")\n",
        "    print(f\"Davies-Bouldin score: {DB_score:.4f}\")\n",
        "\n",
        "    # Create a dictionary to store the evaluation scores\n",
        "    scores_dict = {\"silhouette_score\": S_score,\n",
        "                   \"calinski_harabasz_score\": CH_score,\n",
        "                   \"davies_bouldin_score\": DB_score}\n",
        "                    # Create a dataframe to display the evaluation results\n",
        "    df_eval = pd.DataFrame({\"Evaluation Metric\": [\"Silhouette Score\",\n",
        "                                                  \"Calinski-Harabasz Score\",\n",
        "                                                  \"Davies-Bouldin Score\"],\n",
        "                                     \"Score\": [S_score, CH_score, DB_score]})\n",
        "\n",
        "    # Print the dataframe\n",
        "    print(tabulate(df_eval, headers=\"keys\", tablefmt=\"grid\"))\n",
        "\n",
        "    # Return the evaluation results\n",
        "    return {\"n_clusters\": n_clusters,\n",
        "            \"silhouette_score\": S_score,\n",
        "            \"calinski_harabasz_score\": CH_score,\n",
        "            \"davies_bouldin_score\": DB_score}"
      ],
      "metadata": {
        "id": "-DTLBcmnrqz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_clustering_scores(scores_dict):\n",
        "    \"\"\"\n",
        "    Plot the clustering evaluation scores using a bar chart.\n",
        "    \"\"\"\n",
        "    # Extract the scores from the dictionary\n",
        "    scores = [scores_dict[\"silhouette_score\"], scores_dict[\"calinski_harabasz_score\"], scores_dict[\"davies_bouldin_score\"]]\n",
        "    labels = [\"Silhouette\", \"Calinski-Harabasz\", \"Davies-Bouldin\"]\n",
        "\n",
        "    # Plot the scores as a bar chart\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.bar(labels, scores, color=[\"tab:blue\", \"tab:orange\", \"tab:green\"])\n",
        "\n",
        "    # Add labels and titles\n",
        "    ax.set_xlabel(\"Evaluation Metric\")\n",
        "    ax.set_ylabel(\"Score\")\n",
        "    ax.set_title(\"Clustering Evaluation Scores\")\n",
        "    ax.set_ylim([np.min(scores) - 0.1, np.max(scores) + 0.1])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "E8y4njSOrqts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1: K-MEANS CLUSTERING"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking\n",
        "kmeans = KMeans(n_clusters = 3, max_iter = 50)\n",
        "kmeans.fit(x)"
      ],
      "metadata": {
        "id": "Jw1J_aD9u12d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans.labels_"
      ],
      "metadata": {
        "id": "TJW0Tv1Hu1yQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(x)[:, 0]"
      ],
      "metadata": {
        "id": "e3A4afVgvCmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To Find Optimum Numbers of Clusters\n",
        "\n",
        "# Elbow Method\n",
        "# silhouette Score\n",
        "\n",
        "# Create a list to store the sum of squared errors for each K value\n",
        "Sum_of_Squared_Errors = []\n",
        "\n",
        "# Iterate over range of K values and compute SSE for each value\n",
        "for k in range(1, 10):\n",
        "    # Initialize the k-means model with the current value of K\n",
        "    kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42)\n",
        "    # Fit the model to the data\n",
        "    kmeans.fit(x)\n",
        "    # Compute the sum of squared errors for the model\n",
        "    Sum_of_Squared_Errors.append(kmeans.inertia_)\n",
        "\n",
        "# Plot the SSE values against the range of K values\n",
        "plt.plot(range(1, 10), Sum_of_Squared_Errors)\n",
        "plt.title('Elbow Method for K-Means Clustering')\n",
        "plt.xlabel('Number of clusters (K)')\n",
        "plt.ylabel('Sum of Squared Errors (SSE)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TjBa6dT89Ts4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mA0Hxu5z9Tpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wbwZS7sk9Tlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HRNuSDli9TCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AQI4MKNX9S9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}